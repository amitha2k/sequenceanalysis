{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence Analysis with Python\n",
    "\n",
    "Contact: Veli MÃ¤kinen veli.makinen@helsinki.fi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following assignments introduce applications of hashing with ```dict()``` primitive of Python. While doing so, a rudimentary introduction to biological sequences is given. \n",
    "This framework is then enhanced with probabilities, leading to routines to generate random sequences under some constraints, including a general concept of *Markov-chains*. All these components illustrate the usage of ```dict()```, but at the same time introduce some other computational routines to efficiently deal with probabilities.   \n",
    "The function ```collections.defaultdict``` can be useful.\n",
    "\n",
    "Below are some \"suggested\" imports. Feel free to use and modify these, or not. Generally it's good practice to keep most or all imports in one place. Typically very close to the start of notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.831112Z",
     "start_time": "2019-07-08T22:04:22.688031Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The automated TMC tests do not test cell outputs. These are intended to be evaluated in the peer reviews. So it is still be a good idea to make the outputs as clear and informative as possible.\n",
    "\n",
    "To keep TMC tests running as well as possible it is recommended to keep global variable assignments in the notebook to a minimum to avoid potential name clashes and confusion. Additionally you should keep all actual code exection in main guards to keep the test running smoothly. If you run [check_sequence.py](https://raw.githubusercontent.com/saskeli/data-analysis-with-python-summer-2019/master/check_outputs.py) in the `part07-e01_sequence_analysis` folder, the script should finish very quickly and optimally produce no output.\n",
    "\n",
    "If you download data from the internet during execution (codon usage table), the parts where downloading is done should not work if you decide to submit to the tmc server. Local tests should work fine."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNA and RNA\n",
    "\n",
    "A DNA molecule consist, in principle, of a chain of smaller molecules. These smaller molecules have some common basic components (bases) that repeat. For our purposes it is sufficient to know that these bases are nucleotides adenine, cytosine, guanine, and thymine with abbreviations ```A```, ```C```, ```G```, and ```T```. Given a *DNA sequence* e.g. ```ACGATGAGGCTCAT```, one can reverse engineer (with negligible loss of information) the corresponding DNA molecule.\n",
    "\n",
    "Parts of a DNA molecule can *transcribe* into an RNA molecule. In this process, thymine gets replaced by uracil (```U```). \n",
    "\n",
    "\n",
    "1. Write a function ```dna_to_rna``` to convert a given DNA sequence $s$ into an RNA sequence. For the sake of exercise, use ```dict()``` to store the symbol to symbol encoding rules. Create a program to test your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.841952Z",
     "start_time": "2019-07-08T22:04:22.834721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AACGUGAUUUC\n",
      "\n",
      "U\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dna_to_rna(s):\n",
    "    rules = {\"A\":\"A\",\"C\":\"C\",\"G\":\"G\",\"T\":\"U\"}\n",
    "    res = []\n",
    "    for sym in s:\n",
    "        res.append(rules[sym])\n",
    "    return \"\".join(res)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    print(dna_to_rna(\"AACGTGATTTC\"))\n",
    "    print(dna_to_rna(\"\"))\n",
    "    print(dna_to_rna(\"T\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Since we were asked to use a dictionary to store the rules, I decided to use a for loop that maps each character using the dictionary as a mapping."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The function is correctly converting a string of any given length that represents a DNA sequence to an RNA sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proteins\n",
    "\n",
    "Like DNA and RNA, protein molecule can be interpreted as a chain of smaller molecules, where the bases are now amino acids. RNA molecule may *translate* into a protein molecule, but instead of base by base, three bases of RNA correspond to one base of protein. That is, RNA sequence is read triplet (called codon) at a time. \n",
    "\n",
    "2. Consider the codon to amino acid conversion table in http://htmlpreview.github.io/?https://github.com/csmastersUH/data_analysis_with_python_2020/blob/master/Codon%20usage%20table.html. Write a function ```get_dict``` to read the table into a ```dict()```, such that for each RNA sequence of length 3, say $\\texttt{AGU}$, the hash table stores the conversion rule to the corresponding amino acid. You may store the html page to your local src directory,\n",
    "and parse that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.867855Z",
     "start_time": "2019-07-08T22:04:22.845885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UUU': 'F', 'UCU': 'S', 'UAU': 'Y', 'UGU': 'C', 'UUC': 'F', 'UCC': 'S', 'UAC': 'Y', 'UGC': 'C', 'UUA': 'L', 'UCA': 'S', 'UAA': '*', 'UGA': '*', 'UUG': 'L', 'UCG': 'S', 'UAG': '*', 'UGG': 'W', 'CUU': 'L', 'CCU': 'P', 'CAU': 'H', 'CGU': 'R', 'CUC': 'L', 'CCC': 'P', 'CAC': 'H', 'CGC': 'R', 'CUA': 'L', 'CCA': 'P', 'CAA': 'Q', 'CGA': 'R', 'CUG': 'L', 'CCG': 'P', 'CAG': 'Q', 'CGG': 'R', 'AUU': 'I', 'ACU': 'T', 'AAU': 'N', 'AGU': 'S', 'AUC': 'I', 'ACC': 'T', 'AAC': 'N', 'AGC': 'S', 'AUA': 'I', 'ACA': 'T', 'AAA': 'K', 'AGA': 'R', 'AUG': 'M', 'ACG': 'T', 'AAG': 'K', 'AGG': 'R', 'GUU': 'V', 'GCU': 'A', 'GAU': 'D', 'GGU': 'G', 'GUC': 'V', 'GCC': 'A', 'GAC': 'D', 'GGC': 'G', 'GUA': 'V', 'GCA': 'A', 'GAA': 'E', 'GGA': 'G', 'GUG': 'V', 'GCG': 'A', 'GAG': 'E', 'GGG': 'G'}\n",
      "AAA converts to K\n",
      "UAG converts to *\n",
      "UGG converts to W\n",
      "The total number of codons is 64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_dict():\n",
    "    with open(\"CodonUsageTable.html\",\"r\") as f:\n",
    "        content = f.read()\n",
    "    table = re.findall(r\"[AUGC][AUGC][AUGC] [A-Z|\\*]\",content)\n",
    "    result = {}\n",
    "    for row in table:\n",
    "        pair = row.split()\n",
    "        codon = pair[0]\n",
    "        aa = pair[1]\n",
    "        result[codon] = aa\n",
    "    return result\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    codon_to_aa = get_dict()\n",
    "    print(codon_to_aa)\n",
    "    print(\"AAA converts to\", codon_to_aa[\"AAA\"])\n",
    "    print(\"UAG converts to\", codon_to_aa[\"UAG\"])\n",
    "    print(\"UGG converts to\", codon_to_aa[\"UGG\"])\n",
    "    print(\"The total number of codons is\", len(codon_to_aa))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "Since the data table was the only text in the webpage that was formatted in that way, I used a regular expression to compile all phrases in the page that consisted of a codon followed by an amino acid. This gave me a tuple of strings where each string contained the codon and the amino acid seperated by a space. I then used a loop to add each string into the dictionary with the codn as the key and the amino acid as the value and returned the dictionary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "The dictionary has 64 keys which means the regular expression found all the codons as required. ALso, upon trying random codons, we see that they are being translated to the correct amino acid. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the same conversion table as above, but now write function `get_dict_list` to read the table into a `dict()`, such that for each amino acid the hash table stores the list of codons encoding it.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.882386Z",
     "start_time": "2019-07-08T22:04:22.872449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F': ['UUU', 'UUC'], 'S': ['UCU', 'UCC', 'UCA', 'UCG', 'AGU', 'AGC'], 'Y': ['UAU', 'UAC'], 'C': ['UGU', 'UGC'], 'L': ['UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG'], '*': ['UAA', 'UGA', 'UAG'], 'W': ['UGG'], 'P': ['CCU', 'CCC', 'CCA', 'CCG'], 'H': ['CAU', 'CAC'], 'R': ['CGU', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'], 'Q': ['CAA', 'CAG'], 'I': ['AUU', 'AUC', 'AUA'], 'T': ['ACU', 'ACC', 'ACA', 'ACG'], 'N': ['AAU', 'AAC'], 'K': ['AAA', 'AAG'], 'M': ['AUG'], 'V': ['GUU', 'GUC', 'GUA', 'GUG'], 'A': ['GCU', 'GCC', 'GCA', 'GCG'], 'D': ['GAU', 'GAC'], 'G': ['GGU', 'GGC', 'GGA', 'GGG'], 'E': ['GAA', 'GAG']}\n",
      "C comes from the following codons:  ['UGU', 'UGC']\n",
      "* comes from the following codons:  ['UAA', 'UGA', 'UAG']\n",
      "The total number of codons is 64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_dict_list():\n",
    "    with open(\"CodonUsageTable.html\",\"r\") as f:\n",
    "        content = f.read()\n",
    "    table = re.findall(r\"[AUGC][AUGC][AUGC] [A-Z|\\*]\",content)\n",
    "    result = {}\n",
    "    for row in table:\n",
    "        pair = row.split()\n",
    "        codon = pair[0]\n",
    "        aa = pair[1]\n",
    "        if aa in result:\n",
    "            result[aa].append(codon)\n",
    "        else:\n",
    "            result[aa] = [codon]\n",
    "        \n",
    "    return result\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    aa_to_codons = get_dict_list()\n",
    "    print(aa_to_codons)\n",
    "    print(\"C comes from the following codons: \", aa_to_codons[\"C\"])\n",
    "    print(\"* comes from the following codons: \", aa_to_codons[\"*\"])\n",
    "    total_codons = 0\n",
    "    for aa in aa_to_codons:\n",
    "        total_codons += len(aa_to_codons[aa])\n",
    "    print(\"The total number of codons is\", total_codons)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "Just like in question 2, I used a regular expression to get all the pairs of codons and amino acids as strings containing both of them seperated by a space. I then used a loop to add each unique amino acid to my resulting dictionary as a key if it does not already exist in the dictionary and add the codon that produces it to the list which is its value. So in each step of the loop, one codon gets added to the list of one amino acid from the dictionary or a new key-value pair gets created with the codon-amino-acid pair."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "I counted the total number of codons by adding the length of each value in the dictionary that results from the get_dict_list function. The total comes to 64 which tells me that all codons are included. This is not necessary since the codons may have erroniously repeated so to be certain, I should have merged all the lists together into one list, converted it to a set and then measured the length. However, from lookingat the dictionary and checking the values of some arbitrary amino acids, the functions appear to have the correct output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the conversion tables at hand, the following should be trivial to solve.\n",
    "\n",
    "4. Fill in function ```rna_to_prot``` in the stub solution to convert a given DNA sequence $s$ into a protein sequence. \n",
    "You may use the dictionaries from exercises 2 and 3. You can test your program with `ATGATATCATCGACGATGTAG`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.913321Z",
     "start_time": "2019-07-08T22:04:22.906646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATGATATCATCGACGATGTAG translates to  MISSTM*\n",
      "ACG translates to  T\n",
      "AUGCGCUUUGCAGCC translates to  MRFAA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def rna_to_prot(s):\n",
    "    result = \"\"\n",
    "    for i in range(0,len(s),3):\n",
    "        result += get_dict()[s[i:i+3]]\n",
    "    return result\n",
    "\n",
    "def dna_to_prot(s):\n",
    "    return rna_to_prot(dna_to_rna(s))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"ATGATATCATCGACGATGTAG translates to \",dna_to_prot(\"ATGATATCATCGACGATGTAG\"))\n",
    "    print(\"ACG translates to \", dna_to_prot(\"ACG\"))\n",
    "    print(\"AUGCGCUUUGCAGCC translates to \", rna_to_prot(\"AUGCGCUUUGCAGCC\"))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "The function rna_to_prot runs a for loop through the string s that is made up of codons (which are three characters each). The loop looks up each codon of s in the dictionary resulting from get_dict() which maps each codon to its corresponding amino acid. The value of the key is then appended to the resulting string which is the output of the function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The function runs correctly for a sequence of one or more codons of dna and rna sequences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that there are $4^3=64$ different codons, but only 20 amino acids. That is, some triplets encode the same amino acid.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse translation\n",
    "\n",
    "It has been observed that among the codons coding the same amino acid, some are more frequent than others. These frequencies can be converted to probabilities. E.g. consider codons `AUU`, `AUC`, and `AUA` that code for amino acid isoleucine.\n",
    "If they are observed, say, 36, 47, 17 times, respectively, to code isoleucine in a dataset, the probability that a random such event is `AUU` $\\to$ isoleucine is 36/100.\n",
    "\n",
    "This phenomenon is called *codon adaptation*, and for our purposes it works as a good introduction to generation of random sequences under constraints.   \n",
    "\n",
    "5. Consider the codon adaptation frequencies in http://htmlpreview.github.io/?https://github.com/csmastersUH/data_analysis_with_python_2020/blob/master/Codon%20usage%20table.html and read them into a ```dict()```, such that for each RNA sequence of length 3, say `AGU`, the hash table stores the probability of that codon among codons encoding the same amino acid.\n",
    "Put your solution in the ```get_probabability_dict``` function. Use the column \"([number])\" to estimate the probabilities, as the two preceding columns contain truncated values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.966173Z",
     "start_time": "2019-07-08T22:04:22.956013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAA: 0.434049\tAAC: 0.529633\tAAG: 0.565951\tAAU: 0.470367\tACA: 0.284188\tACC: 0.355232\n",
      "ACG: 0.113812\tACU: 0.246769\tAGA: 0.214658\tAGC: 0.239938\tAGG: 0.211091\tAGU: 0.149602\n",
      "AUA: 0.169062\tAUC: 0.469866\tAUG: 1.000000\tAUU: 0.361072\tCAA: 0.265017\tCAC: 0.581485\n",
      "CAG: 0.734983\tCAU: 0.418515\tCCA: 0.276603\tCCC: 0.323470\tCCG: 0.113196\tCCU: 0.286731\n",
      "CGA: 0.108812\tCGC: 0.183777\tCGG: 0.201554\tCGU: 0.080108\tCUA: 0.071380\tCUC: 0.195577\n",
      "CUG: 0.395702\tCUU: 0.131716\tGAA: 0.422453\tGAC: 0.535458\tGAG: 0.577547\tGAU: 0.464542\n",
      "GCA: 0.228121\tGCC: 0.399781\tGCG: 0.106176\tGCU: 0.265922\tGGA: 0.249922\tGGC: 0.337109\n",
      "GGG: 0.249882\tGGU: 0.163087\tGUA: 0.116577\tGUC: 0.238306\tGUG: 0.463346\tGUU: 0.181770\n",
      "UAA: 0.297019\tUAC: 0.556662\tUAG: 0.236738\tUAU: 0.443338\tUCA: 0.150517\tUCC: 0.217960\n",
      "UCG: 0.054398\tUCU: 0.187586\tUGA: 0.466243\tUGC: 0.543843\tUGG: 1.000000\tUGU: 0.456157\n",
      "UUA: 0.076568\tUUC: 0.535866\tUUG: 0.129058\tUUU: 0.464134\n",
      "The number of codons are  64\n",
      "\n",
      "Here are the truncated fraction values from the Codon Usage Table:\n",
      "AAA: 0.430000\tAAC: 0.530000\tAAG: 0.570000\tAAU: 0.470000\tACA: 0.280000\tACC: 0.360000\n",
      "ACG: 0.110000\tACU: 0.250000\tAGA: 0.210000\tAGC: 0.240000\tAGG: 0.210000\tAGU: 0.150000\n",
      "AUA: 0.170000\tAUC: 0.470000\tAUG: 1.000000\tAUU: 0.360000\tCAA: 0.270000\tCAC: 0.580000\n",
      "CAG: 0.730000\tCAU: 0.420000\tCCA: 0.280000\tCCC: 0.320000\tCCG: 0.110000\tCCU: 0.290000\n",
      "CGA: 0.110000\tCGC: 0.180000\tCGG: 0.200000\tCGU: 0.080000\tCUA: 0.070000\tCUC: 0.200000\n",
      "CUG: 0.400000\tCUU: 0.130000\tGAA: 0.420000\tGAC: 0.540000\tGAG: 0.580000\tGAU: 0.460000\n",
      "GCA: 0.230000\tGCC: 0.400000\tGCG: 0.110000\tGCU: 0.270000\tGGA: 0.250000\tGGC: 0.340000\n",
      "GGG: 0.250000\tGGU: 0.160000\tGUA: 0.120000\tGUC: 0.240000\tGUG: 0.460000\tGUU: 0.180000\n",
      "UAA: 0.300000\tUAC: 0.560000\tUAG: 0.240000\tUAU: 0.440000\tUCA: 0.150000\tUCC: 0.220000\n",
      "UCG: 0.050000\tUCU: 0.190000\tUGA: 0.470000\tUGC: 0.540000\tUGG: 1.000000\tUGU: 0.460000\n",
      "UUA: 0.080000\tUUC: 0.540000\tUUG: 0.130000\tUUU: 0.460000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_probabability_dict():\n",
    "    with open(\"CodonUsageTable.html\",\"r\") as f:\n",
    "        content = f.read()\n",
    "    table = re.findall(r'([AUGC][AUGC][AUGC])\\s+([A-Z|\\*])\\s+\\d+\\.\\d+\\s+\\d+\\.\\d+\\s+\\(\\s*(\\d+)\\s*\\)',content)\n",
    "    aa_totals = {}\n",
    "    for row in table:\n",
    "        if row[1] in aa_totals:\n",
    "            aa_totals[row[1]] += int(row[2])\n",
    "        else:\n",
    "            aa_totals[row[1]] = int(row[2])\n",
    "    prob_dict = {}\n",
    "    for row in table:\n",
    "        prob_dict[row[0]] = int(row[2])/aa_totals[row[1]]\n",
    "    return prob_dict\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    codon_to_prob = get_probabability_dict()\n",
    "    items = sorted(codon_to_prob.items(), key=lambda x: x[0])\n",
    "    for i in range(1 + len(items)//6):\n",
    "        print(\"\\t\".join(\n",
    "            f\"{k}: {v:.6f}\"\n",
    "            for k, v in items[i*6:6+i*6]\n",
    "        ))\n",
    "    print(\"The number of codons are \", len(get_probabability_dict()))\n",
    "\n",
    "    #printing the fraction column instead to see if the calculations match:\n",
    "    print(\"\\nHere are the truncated fraction values from the Codon Usage Table:\")\n",
    "    with open(\"CodonUsageTable.html\",\"r\") as f:\n",
    "        content = f.read()\n",
    "    fractions = re.findall(r'([AUGC][AUGC][AUGC])\\s+[A-Z|\\*]\\s+(\\d+\\.\\d+)',content)\n",
    "    usage_table = {}\n",
    "    for row in fractions:\n",
    "        usage_table[row[0]] = float(row[1])\n",
    "    usage_table_items = sorted(usage_table.items(), key=lambda x: x[0])\n",
    "    for i in range(1 + len(usage_table_items)//6):\n",
    "        print(\"\\t\".join(\n",
    "            f\"{k}: {v:.6f}\"\n",
    "            for k, v in usage_table_items[i*6:6+i*6]\n",
    "        ))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "I first used a regular expression to find all the triples in the html file correspinding to the name of the codon, the amino acid it encodes, and its frequency. Next, by running a for loop through this list of triples, I created a dictionary called aa_totals where the keys are all the possible amino acids and their values are the sum of frequencies of all codons encoding them. Finally, to create the probability dictionary, I ran a for loop through the list of triples. I set the keys to be the codons and their values to be thier frequency divided by the value of the amino acid it encodes from the aa_totals dictionary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "To test it out, I simply printed the resulting dictionary and also checked that its length is 64 as that is the number of possibilities of codons. I also used a regular expression to print the fraction column from the html page as a dictionary, which represents the same values as the values in get_probability_dict but rounded to two decimal places. By looking at both the dictionaries side by side we see that the values in both dictionaries are equal  when rounded to 2 decimal places so the calculations are correct."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should have everything in place to easily solve the following.\n",
    "\n",
    "\n",
    "6. Write a class ```ProteinToMaxRNA``` with a ```convert``` method which converts a protein sequence into the most likely RNA sequence to be the source of this protein. Run your program with `LTPIQNRA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.000743Z",
     "start_time": "2019-07-08T22:04:22.992108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LTPIQNRA converts to CUGACCCCCAUCCAGAACAGAGCC\n",
      "Empty string converts to \n",
      "* converts to UGA\n",
      "In aa_to_codons dictionary, * has this value: ['UAA', 'UGA', 'UAG']\n",
      "The probabilities of the codons encoded by * are:  [0.29701911804823383, 0.46624296805302623, 0.23673791389873997]\n"
     ]
    }
   ],
   "source": [
    "class ProteinToMaxRNA:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def convert(self, s):\n",
    "        codon_probs = get_probabability_dict()\n",
    "        aa_to_codons = get_dict_list()\n",
    "        rna = \"\"\n",
    "        for aa in s:\n",
    "            max_codon = aa_to_codons[aa][0]\n",
    "            for codon in aa_to_codons[aa]:\n",
    "                if codon_probs[max_codon] < codon_probs[codon]:\n",
    "                    max_codon = codon\n",
    "            rna += max_codon\n",
    "        return rna\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    protein_to_rna = ProteinToMaxRNA()\n",
    "    print(\"LTPIQNRA converts to\", protein_to_rna.convert(\"LTPIQNRA\"))\n",
    "    protein_to_rna2 = ProteinToMaxRNA()\n",
    "    print(\"Empty string converts to\", protein_to_rna2.convert(\"\"))\n",
    "    protein_to_rna3 = ProteinToMaxRNA()\n",
    "    star_to_rna = protein_to_rna2.convert(\"*\")\n",
    "    print(\"* converts to\", protein_to_rna2.convert(\"*\"))\n",
    "    print(\"In aa_to_codons dictionary, * has this value:\", get_dict_list()[\"*\"])\n",
    "    print(\"The probabilities of the codons encoded by * are: \", list(get_probabability_dict()[i] for i in get_dict_list()[\"*\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "For each amino acid in s which represents a protein, I looked up the amino acid in the dictionary get_dict_list() to get the list of all codons that encode it. I then looked up each of these codons in the dictionary get_probability_dict() to compare their probabilities and find the one with the highest probability. The codon with the highest probability was appended to my resulting string rna in which I accumulated the codons with highest probability for each amino acid.\n",
    "\n",
    "I did not edit the init function as I could not think of any attributes I might need to initialise in order to complete the code for the convert method. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The given example \"LTPIQNRA\" outputs a valid rna sequence however we do not know from this example if the output is the most probable one. So we run another test on a single amino acid, \"*\". Upon looking up the probabilities of each of the codons that encode * using the dictionaries get_dict_list() and get_probability_dict(), we see that the correct codon is being returned by our method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are almost ready to produce random RNA sequences that code a given protein sequence. For this, we need a subroutine to *sample from a probability distribution*. Consider our earlier example of probabilities 36/100, 47/100, and 17/100 for `AUU`, `AUC`, and `AUA`, respectively. \n",
    "Let us assume we have a random number generator ```random()``` that returns a random number from interval $[0,1)$. We may then partition the unit interval according to cumulative probabilities to $[0,36/100), [36/100,83/100), [83/100,1)$, respectively. Depending which interval the number ```random()``` hits, we select the codon accordingly.\n",
    "\n",
    "7. Write a function ```random_event``` that chooses a random event, given a probability distribution (set of events whose probabilities sum to 1).\n",
    "You can use function ```random.uniform``` to produce values uniformly at random from the range $[0,1)$. The distribution should be given to your function as a dictionary from events to their probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.036655Z",
     "start_time": "2019-07-08T22:04:23.030067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G, T, C, A, G, G, C, C, G, C, T, C, G, G, C, T, T, T, C, A, C, T, C, C, T, G, T, C, A\n",
      "Distribution:  \n",
      "A:  0.10344827586206896 \n",
      "C:  0.3793103448275862 \n",
      "G:  0.2413793103448276 \n",
      "T:  0.27586206896551724\n",
      "T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T, T\n",
      "Distribution:  \n",
      "A:  0.0 \n",
      "C:  0.0 \n",
      "G:  0.0 \n",
      "T:  1.0\n"
     ]
    }
   ],
   "source": [
    "def random_event(dist):\n",
    "    \"\"\"\n",
    "    Takes as input a dictionary from events to their probabilities.\n",
    "    Return a random event sampled according to the given distribution.\n",
    "    The probabilities must sum to 1.0\n",
    "    \"\"\"\n",
    "    cumulative = {}\n",
    "    so_far = 0\n",
    "    for event in dist:\n",
    "        cumulative[event] = (so_far, dist[event] + so_far)\n",
    "        so_far += dist[event]\n",
    "    random_gen = np.random.uniform()\n",
    "    for event in dist:\n",
    "        if cumulative[event][0]<= random_gen < cumulative[event][1]:\n",
    "            return event\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    distribution = dict(zip(\"ACGT\", [0.10, 0.35, 0.15, 0.40]))\n",
    "    test_output = \", \".join(random_event(distribution) for _ in range(29))\n",
    "    print(test_output)\n",
    "    print(\"Distribution: \", \"\\nA: \", test_output.count(\"A\")/29, \"\\nC: \", test_output.count(\"C\")/29, \"\\nG: \", test_output.count(\"G\")/29, \n",
    "    \"\\nT: \", test_output.count(\"T\")/29)\n",
    "\n",
    "    distribution2 = dict(zip(\"ACGT\", [0, 0, 0, 1]))\n",
    "    test_output2 = \", \".join(random_event(distribution2) for _ in range(29))\n",
    "    print(test_output2)\n",
    "    print(\"Distribution: \", \"\\nA: \", test_output2.count(\"A\")/29, \"\\nC: \", test_output2.count(\"C\")/29, \"\\nG: \", test_output2.count(\"G\")/29, \n",
    "    \"\\nT: \", test_output2.count(\"T\")/29)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "I first split up the interval [0,1) into intervals of sizes given by the distribution in dist. To do so, I created a new dictionary with the same keys as dist but for each key, I added the probabilites of the previous keys to the probability of each key. These intervals are represented as values in my new dictionary, \"cumulative\", in the form of lists containing two values, the lower bound and the upper bound.\n",
    "\n",
    "Afer this, I generated a random number in the interval [0,1) using the given function and looked at each value in my cumulative dictionary to find the key whose interval contains the generated number (upper bound is excluded). This key is returned. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "In order to test this function, I generated bases with two distributions and for each one, I calculated the proportion of each base to see if it is roughly close to the input distributions. I ran the function a few times since the random generation is always difference and for the first test, I always get something close to the input distribution. The second distribution is trivial is so the proportion is always the same as the input distribution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this general routine, the following should be easy to solve.\n",
    " \n",
    "8. Write a class ```ProteinToRandomRNA``` to produce a random RNA sequence encoding the input protein sequence according to the input codon adaptation probabilities. The actual conversion is done through the ```convert``` method. Run your program with `LTPIQNRA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.073660Z",
     "start_time": "2019-07-08T22:04:23.067966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUUACUCCCAUACAAAACAGGGCC\n",
      "The length of the input is  8\n",
      "the number of codons in the output is 8.0\n",
      "CUC\n",
      "['UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG']\n",
      "AUC\n",
      "['AUU', 'AUC', 'AUA']\n",
      "AAU\n",
      "['AAU', 'AAC']\n"
     ]
    }
   ],
   "source": [
    "class ProteinToRandomRNA(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def convert(self, s):\n",
    "        result = \"\"\n",
    "        for aa in s:\n",
    "            codons = get_dict_list()[aa]\n",
    "            dist = {}\n",
    "            for codon in codons:\n",
    "                dist[codon] = get_probabability_dict()[codon]\n",
    "            result += random_event(dist)\n",
    "        return result\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    protein_to_random_codons = ProteinToRandomRNA()\n",
    "    print(protein_to_random_codons.convert(\"LTPIQNRA\"))\n",
    "    print(\"The length of the input is \", len(\"LTPIQNRA\"))\n",
    "    print(\"the number of codons in the output is\", len(protein_to_random_codons.convert(\"LTPIQRNA\"))/3)\n",
    "    print(protein_to_random_codons.convert(\"L\"))\n",
    "    print(get_dict_list()[\"L\"])\n",
    "    print(protein_to_random_codons.convert(\"I\"))\n",
    "    print(get_dict_list()[\"I\"])\n",
    "    print(protein_to_random_codons.convert(\"N\"))\n",
    "    print(get_dict_list()[\"N\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "For each amino acid in s, I looked it up in the dictionary get_dict_list() to get the list of codons that encode it. Then, I created a distribution dictionary for each of the codons by looking up each codon in the dictionary get_probabilty_dict(). The distribution dictionary contained the codons as keys and their probabilities as values. I ran the function random_event with this distribution as its input to get a random codon based on the distribution. I appended each resulting codon into the resulting string."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The first test is the given protein sequence which looks like a valid rna sequence since it contains codons and the correct number of codons. To check if the codons are those that encode the amino acid, we run this function on three arbitrary amino acids and check whether the output is one of the values in the list associated with that amino acid in get_dict_list(). The three amino acids passed the test."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating DNA sequences with higher-order Markov chains\n",
    "\n",
    "We will now reuse the machinery derived above in a related context. We go back to DNA sequences, and consider some easy statistics that can be used to characterize the sequences. \n",
    "First, just the frequencies of bases $\\texttt{A}$, $\\texttt{C}$, $\\texttt{G}$, $\\texttt{T}$ may reveal the species from which the input DNA originates; each species has a different base composition that has been formed during evolution. \n",
    "More interestingly, the areas where DNA to RNA transcription takes place (coding region) have an excess of $\\texttt{C}$ and $\\texttt{G}$ over $\\texttt{A}$ and $\\texttt{T}$. To detect such areas a common routine is to just use a *sliding window* of fixed size, say $k$, and compute for each window position \n",
    "$T[i..i+k-1]$ the base frequencies, where $T[1..n]$ is the input DNA sequence. When sliding the window from  $T[i..i+k-1]$ to $T[i+1..i+k]$ frequency $f(T[i])$ gets decreases by one and $f(T[i+k])$ gets increased by one. \n",
    "\n",
    "9. Write a *generator* ```sliding_window``` to compute sliding window base frequencies so that each moving of the window takes constant time. We saw in the beginning of the course one way how to create generators using\n",
    "  generator expression. Here we use a different way. For the function ```sliding_window``` to be a generator, it must have at least   one ```yield``` expression, see [https://docs.python.org/3/reference/expressions.html#yieldexpr](https://docs.python.org/3/reference/expressions.html#yieldexpr).\n",
    "  \n",
    "  Here is an example of a generator expression that works similarily to the built in `range` generator:\n",
    "  ```Python\n",
    "  def range(a, b=None, c=1):\n",
    "      current = 0 if b == None else a\n",
    "      end = a if b == None else b\n",
    "      while current < end:\n",
    "          yield current\n",
    "          current += c\n",
    "  ```\n",
    "  A yield expression can be used to return a value and *temporarily* return from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.111365Z",
     "start_time": "2019-07-08T22:04:23.100858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'G': 0, 'C': 3, 'T': 1} total:  4\n",
      "{'A': 0, 'G': 1, 'C': 3, 'T': 0} total:  4\n",
      "{'A': 1, 'G': 1, 'C': 2, 'T': 0} total:  4\n",
      "{'A': 1, 'G': 1, 'C': 2, 'T': 0} total:  4\n",
      "{'A': 1, 'G': 2, 'C': 1, 'T': 0} total:  4\n",
      "{'A': 1, 'G': 2, 'C': 1, 'T': 0} total:  4\n",
      "{'A': 0, 'G': 2, 'C': 2, 'T': 0} total:  4\n",
      "{'A': 0, 'G': 2, 'C': 2, 'T': 0} total:  4\n",
      "{'A': 0, 'G': 1, 'C': 2, 'T': 1} total:  4\n",
      "{'A': 0, 'G': 0, 'C': 2, 'T': 2} total:  4\n",
      "{'A': 0, 'G': 1, 'C': 1, 'T': 2} total:  4\n",
      "{'A': 0, 'G': 1, 'C': 1, 'T': 2} total:  4\n",
      "{'A': 0, 'G': 1, 'C': 2, 'T': 1} total:  4\n",
      "The no. of dictionaries is  13\n",
      "len(s):  16\n",
      "----------\n",
      "{'A': 1, 'G': 1, 'C': 1, 'T': 0} total:  3\n"
     ]
    }
   ],
   "source": [
    "def sliding_window(s, k):\n",
    "    \"\"\"\n",
    "    This function returns a generator that can be iterated over all\n",
    "    starting position of a k-window in the sequence.\n",
    "    For each starting position the generator returns the nucleotide frequencies\n",
    "    in the window as a dictionary.\n",
    "    \"\"\"\n",
    "    first_window = s[:k]\n",
    "    frequencies = {}\n",
    "    frequencies[\"A\"] = first_window.count(\"A\")\n",
    "    frequencies[\"G\"] = first_window.count(\"G\")\n",
    "    frequencies[\"C\"] = first_window.count(\"C\")\n",
    "    frequencies[\"T\"] = first_window.count(\"T\")\n",
    "    \n",
    "    for i in range(len(s)-k+1):\n",
    "        yield frequencies\n",
    "        frequencies[s[i]] -= 1\n",
    "        if i+k < len(s):\n",
    "            frequencies[s[i+k]] += 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    s = \"TCCCGACGGCCTTGCC\"\n",
    "    for d in sliding_window(s, 4):\n",
    "        count = 0\n",
    "        for base in d:\n",
    "            count += d[base]\n",
    "        print(d, \"total: \", count)\n",
    "    print(\"The no. of dictionaries is \", len(list(sliding_window(s,4))))\n",
    "    print(\"len(s): \", len(s))\n",
    "\n",
    "    print(\"----------\")\n",
    "\n",
    "    t = \"ACG\"\n",
    "    for d in sliding_window(t, 3):\n",
    "        print(d, end=\" \")\n",
    "        count = 0\n",
    "        for base in d:\n",
    "            count += d[base]\n",
    "        print(\"total: \", count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "As suggested above, I start by counting the occurences of each base in the first k bases of the string s which is the substring of s with starting position 0 and ending position k-1. I made this into the dictionary for the first window. For each remaining window, I looped through the possible starting positions which go from 0 to len(s)-k, and modified the dictionary based on the position. For the first iteration, the dictionary yielded is the one created above for the first window. Before yielding the dictionary for the next window, we reduce the count of the first character froom the current window and increase the count of the last character of the next window in the dictionary that was yielded. After making these changes, the new dictionary is yielded. The same continues until we reach the last window."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The given example outputs the right total count in each dictionary. We also see that it produces the right number of dictionaries since there are 16 characters so the last window of length 4 would start at the 13th character.\n",
    "\n",
    "Finally, to check if the counts are right, we try a string s with only one window and can observe that the counts for the dictionary outputted are correct."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Our models so far have been so-called *zero-order* models, as each event has been independent of other events. With sequences, the dependencies of events are naturally encoded by their *contexts*. Considering that a sequence is produced from left-to-right, a *first-order* context for $T[i]$ is $T[i-1]$, that is, the immediately preceding symbol. *First-order Markov chain* is a sequence produced by generating $c=T[i]$ with the probability of event of seeing symbol $c$ after previously generated symbol $a=T[i-1]$. The first symbol of the chain is sampled according to the zero-order model.  \n",
    "The first-order model can naturally be extended to contexts of length $k$, with $T[i]$ depending on $T[i-k..i-1]$. Then the first $k$ symbols of the chain are sampled according to the zero-order model.  The following assignments develop the routines to work with the *higher-order Markov chains*. \n",
    "In what follows, a $k$-mer is a substring $T[i..i+k-1]$ of the sequence at an arbitrary position. \n",
    "\n",
    "10. Write function ```context_list``` that given an input DNA sequence $T$ associates to each $k$-mer $W$ the concatenation of all symbols $c$ that appear after context $W$ in $T$, that is, $T[i..i+k]=Wc$. For example, <span style=\"color:red; font:courier;\">GA</span> is associated to <span style=\"color:blue; font: courier;\">TCT</span> in $T$=<span style=\"font: courier;\">AT<span style=\"color:red;\">GA</span><span style=\"color:blue;\">T</span>ATCATC<span style=\"color:red;\">GA</span><span style=\"color:blue;\">C</span><span style=\"color:red;\">GA</span><span style=\"color:blue;\">T</span>GTAG</span>, when $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.168108Z",
     "start_time": "2019-07-08T22:04:23.162648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AT': 'GACCC', 'TG': 'A', 'GA': 'TCT', 'TA': 'TG', 'TC': 'AGT', 'CA': 'T', 'CG': 'AA', 'AC': 'G', 'CT': 'A'}\n",
      "total:  19\n",
      "len(s):  21\n",
      "{'': 'ATGATATCATCGACGATCTAG'}\n"
     ]
    }
   ],
   "source": [
    "def context_list(s, k):\n",
    "    CL = {}\n",
    "    for i in range(len(s)-k):\n",
    "        curr_kmer = s[i:i+k]\n",
    "        if curr_kmer in CL:\n",
    "            CL[curr_kmer] += s[i+k]\n",
    "        else:\n",
    "            CL[curr_kmer] = s[i+k]\n",
    "    return CL\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATCTAG\"\n",
    "    d = context_list(s, k)\n",
    "    total = 0\n",
    "    for kmer in d:\n",
    "        total += len(d[kmer])\n",
    "    print(d)\n",
    "    print(\"total: \", total)\n",
    "    print(\"len(s): \", len(s))\n",
    "    print(context_list(s,0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "I created an empty dictioanry and then looped through each substring of s of size k. If the substring was not int he dictionary already, I added it as a key and its value was a string containing the character following the substring. If the substring was already in the dictionary, I updated its value by appending the character following the substring to the string which was its current value. This dictionary is returned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The function successfully outputs a dictionary with all 2-mers in the given string as keys. The total number of symbols accumulated by all the 2-mers adds up to 19 which is correct since the first and second characters do not follow any 2-mers and there are 21 characters in total. We also see that setting k to 0 gives one possible k-mer which is the empty string and the value is a concatenation of every character in s which is also correct."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. With the above solution, write function ```context_probabilities``` to count the frequencies of symbols in each context and convert these frequencies into probabilities. Run `context_probabilities` with $T=$ `ATGATATCATCGACGATGTAG` and $k$ values 0 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.218964Z",
     "start_time": "2019-07-08T22:04:23.213773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AT': {'A': 0.2, 'C': 0.4, 'G': 0.4, 'T': 0.0}, 'TG': {'A': 0.5, 'C': 0.0, 'G': 0.0, 'T': 0.5}, 'GA': {'A': 0.0, 'C': 0.3333333333333333, 'G': 0.0, 'T': 0.6666666666666666}, 'TA': {'A': 0.0, 'C': 0.0, 'G': 0.5, 'T': 0.5}, 'TC': {'A': 0.5, 'C': 0.0, 'G': 0.5, 'T': 0.0}, 'CA': {'A': 0.0, 'C': 0.0, 'G': 0.0, 'T': 1.0}, 'CG': {'A': 1.0, 'C': 0.0, 'G': 0.0, 'T': 0.0}, 'AC': {'A': 0.0, 'C': 0.0, 'G': 1.0, 'T': 0.0}, 'GT': {'A': 1.0, 'C': 0.0, 'G': 0.0, 'T': 0.0}}\n",
      "{'AT': 'GACCG', 'TG': 'AT', 'GA': 'TCT', 'TA': 'TG', 'TC': 'AG', 'CA': 'T', 'CG': 'AA', 'AC': 'G', 'GT': 'A'}\n",
      "{'': {'A': 0.3333333333333333, 'C': 0.14285714285714285, 'G': 0.23809523809523808, 'T': 0.2857142857142857}}\n",
      "A: 7 C: 3 G: 5 T: 6\n",
      "total: 21\n"
     ]
    }
   ],
   "source": [
    "def context_probabilities(s, k):\n",
    "    CL = context_list(s,k)\n",
    "    CP = {}\n",
    "    for context in CL:\n",
    "        symbols = CL[context]\n",
    "        total = len(symbols)\n",
    "        prob_A = symbols.count(\"A\")/total\n",
    "        prob_C = symbols.count(\"C\")/total\n",
    "        prob_G = symbols.count(\"G\")/total\n",
    "        prob_T = symbols.count(\"T\")/total\n",
    "        CP[context] = {\"A\":prob_A, \"C\":prob_C, \"G\":prob_G, \"T\":prob_T}\n",
    "    return CP\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    k1 = 0\n",
    "    k2 = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    print(context_probabilities(s,k2))\n",
    "    print(context_list(s,k2))\n",
    "    print(context_probabilities(s,k1))\n",
    "    print(\"A:\", s.count(\"A\"), \"C:\", s.count(\"C\"), \"G:\", s.count(\"G\"), \"T:\", s.count(\"T\"))\n",
    "    print(\"total:\", len(s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "I first ran the function context_list(s,k) to get the dictionary of all k-mers in s whose values are the concatenation of all symbols following the k-mer in s. I ran a for loop such that each k-mer, we get its value from context_list and use the string method count to count the occurences of each of the 4 bases. I divided these counts by the length of the concatenation which is the total number of symbols that followed these k-mers. I then created a dictionary containing each base as a key and the aforementioned quotient as its value. Finally, I created a dictionary and added each k-mer from the above for loop into this dictionary as a key whose value is set to the dictionary of probabilities that I computed. This dictionary is returned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "I ran the context_probabilities function on the given string s and also the context_list function to compare the probabilities. 'AT' has the value 'GACCG' in context_list so the distributions should be 2/5 for G and C, 1/5 for A and 0 for T and we can see that this has been correctly outputted.\n",
    "\n",
    "When k is set to 0, the dictionary that is the key of the empty string should just give the proportion of the string that contains each base. By looking at the counts of each base in string s dividing it by the length of s, we see that values in the dictionary are correct.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. With the above solution and the function ```random_event``` from the earlier exercise, write class ```MarkovChain```. Its ```generate``` method should generate a random DNA sequence following the original $k$-th order Markov chain probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.279315Z",
     "start_time": "2019-07-08T22:04:23.253983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sequence of length 10:  TGTATGATGA\n",
      "A sequence of length 0:  \n",
      "A sequence of length less than k:  T\n"
     ]
    }
   ],
   "source": [
    "class MarkovChain:\n",
    "    \n",
    "    def __init__(self, zeroth, kth, k=2):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "        \n",
    "    def generate(self, n, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        res = \"\"\n",
    "        if n < self.k:\n",
    "            first_few = n\n",
    "        else:\n",
    "            first_few = self.k\n",
    "        for i in range(first_few):\n",
    "            res += random_event(self.zeroth)\n",
    "        while len(res) < n:\n",
    "            context = res[-1*self.k:]\n",
    "            if context in self.kth:\n",
    "                res += random_event(self.kth[context])\n",
    "            else:\n",
    "                res += random_event(self.zeroth)\n",
    "        return res\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    zeroth = {'A': 0.2, 'C': 0.19, 'T': 0.31, 'G': 0.3}\n",
    "    kth = {'GT': {'A': 1.0, 'C': 0.0, 'T': 0.0, 'G': 0.0},\n",
    "           'CA': {'A': 0.0, 'C': 0.0, 'T': 1.0, 'G': 0.0},\n",
    "           'TC': {'A': 0.5, 'C': 0.0, 'T': 0.0, 'G': 0.5},\n",
    "           'GA': {'A': 0.0, 'C': 0.3333333333333333, 'T': 0.6666666666666666, 'G': 0.0},\n",
    "           'TG': {'A': 0.5, 'C': 0.0, 'T': 0.5, 'G': 0.0},\n",
    "           'AT': {'A': 0.2, 'C': 0.4, 'T': 0.0, 'G': 0.4},\n",
    "           'TA': {'A': 0.0, 'C': 0.0, 'T': 0.5, 'G': 0.5},\n",
    "           'AC': {'A': 0.0, 'C': 0.0, 'T': 0.0, 'G': 1.0},\n",
    "           'CG': {'A': 1.0, 'C': 0.0, 'T': 0.0, 'G': 0.0}}\n",
    "   \n",
    "    mc = MarkovChain(zeroth, kth)\n",
    "    print(\"A sequence of length 10: \", mc.generate(10, 0))\n",
    "\n",
    "    mc = MarkovChain(zeroth, kth)\n",
    "    print(\"A sequence of length 0: \", mc.generate(0, 0))\n",
    "\n",
    "    mc = MarkovChain(zeroth, kth)\n",
    "    print(\"A sequence of length less than k: \", mc.generate(1, 0)) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "We are required to generate a string of n characters. For the first k characters (or for all the characters if n is less than k), I used the probability distribution given in zeroth and plugged it into the function random_event which generates one of the events in the given dictionary based on their probabilities which are the values of the dictionary. To generate the remaining characters, I used a while loop that appended a character generated by random_event with the kth dictionary as its input to the resulting string until the resulting string (res) reached a length of n. This resulting string was returned once the loop ended. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "We can see that the generate method successfully generates a sequence of length 10 and also one of length 1 which is less than k=2. It also works for a input length 0 and correctly generates an empty string. It would be tough to check whether the generation is coherent with the given input distribution as it is randomly generated, and I am unable to test the same."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have survived so far without problems, please run your program a few more times with different inputs. At some point you should get a lookup error in your hash-table! The reason for this is not your code, but the way we defined the model: Some $k$-mers may not be among the training data (input sequence $T$), but such can be generated as the first $k$-mer that is generated using the zero-order model.  \n",
    "\n",
    "A general approach to fixing such issues with incomplete training data is to use *pseudo counts*. That is, all imaginable events are initialized to frequency count 1.   \n",
    "\n",
    "13. Write a new solution `context_pseudo_probabilities` based on the solution to problem 11. But this time use pseudo counts in order to obtain a $k$-th order Markov chain that can assign a probability for any DNA sequence. You may use the standard library function `itertools.product` to iterate over all $k$-mer of given length (`product(\"ACGT\", repeat=k)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.303566Z",
     "start_time": "2019-07-08T22:04:23.296028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeroth: {'A': 0.32, 'C': 0.16, 'G': 0.24, 'T': 0.28}\n",
      "Counts: A: 8 C: 4 G: 6 T: 7 total: 25\n",
      "AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AC: {'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
      "AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AT: {'A': 0.2222222222222222, 'C': 0.3333333333333333, 'G': 0.3333333333333333, 'T': 0.1111111111111111}\n",
      "CA: {'A': 0.2, 'C': 0.2, 'G': 0.2, 'T': 0.4}\n",
      "CC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "CG: {'A': 0.5, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.16666666666666666}\n",
      "CT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GA: {'A': 0.14285714285714285, 'C': 0.2857142857142857, 'G': 0.14285714285714285, 'T': 0.42857142857142855}\n",
      "GC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GT: {'A': 0.4, 'C': 0.2, 'G': 0.2, 'T': 0.2}\n",
      "TA: {'A': 0.16666666666666666, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.3333333333333333}\n",
      "TC: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.16666666666666666}\n",
      "TG: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.3333333333333333}\n",
      "TT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "context list of CG: AA\n",
      "\n",
      " CTGGCGCAATATAGTGAAAC\n"
     ]
    }
   ],
   "source": [
    "def context_pseudo_probabilities(s, k):\n",
    "    CL = context_list(s,k)\n",
    "    CP = {}\n",
    "    all_kmers = []\n",
    "    for i in product(\"ACGT\", repeat=k):\n",
    "        all_kmers.append(\"\".join(i))\n",
    "    for kmer in all_kmers:\n",
    "        CP[kmer] = {\"A\":1, \"C\":1, \"G\":1, \"T\":1}\n",
    "    for context in CL:\n",
    "        symbols = CL[context]\n",
    "        CP[context]['A'] += symbols.count(\"A\")\n",
    "        CP[context]['C'] += symbols.count(\"C\")\n",
    "        CP[context]['G'] += symbols.count(\"G\")\n",
    "        CP[context]['T'] += symbols.count(\"T\")\n",
    "    for context in CP:\n",
    "        total = CP[context]['A']+CP[context]['C']+CP[context]['G']+CP[context]['T']\n",
    "        CP[context]['A'] /= total\n",
    "        CP[context]['C'] /= total\n",
    "        CP[context]['G'] /= total\n",
    "        CP[context]['T'] /= total\n",
    "    \n",
    "    return CP\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    kth_2 = context_pseudo_probabilities(s, k)\n",
    "    zeroth2 = context_pseudo_probabilities(s, 0)[\"\"]\n",
    "    print(f\"zeroth: {zeroth2}\")\n",
    "    print(\"Counts: A:\", s.count(\"A\")+1, \"C:\", s.count(\"C\")+1, \"G:\", s.count(\"G\")+1, \"T:\", s.count(\"T\")+1, \"total:\", len(s)+4)\n",
    "    print(\"\\n\".join(f\"{k}: {dict(v)}\" for k, v in kth_2.items()))\n",
    "    print(\"context list of CG:\", context_list(s,k)[\"CG\"])\n",
    "    print(\"\\n\", MarkovChain(zeroth2, kth_2, k).generate(20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "I first got a list of all the k-mers by using the product function and looping through each tuple and converting it into a string k-mer before appending it to my list of k-mers. I then ran a for loop through my list of k-mers and created a dictionary that contains the k-mers as keys and a dictionary containing the frequency count of A,C,G and T as their values. In this for loop, I set the frequency count of every letter for every k-mer to be 1. I ran another for loop through the context list of the given string which I obtained using the context_list function. For each k-mer in the context list, its value contains a concatenation of all letters that followed this k-mer in s. I counted the frequency of each letter in this concatenation during the count method and then added the count to the respective frequency dictionary. \n",
    "Finally, I ran another for loop through the dictionary of k-mers I have and divided each frequency count in the values of the dictionary by the sum of the frequencies for each k-mer.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "First, to check the zeroth dictionary, I printed the frequency of each letter in the string s and added 1 to account the initialization of frequencies to 1. I also printed the total length of the string s plus 4 to account for the initialization. Comparing the numbers 0.32,0.16,0.24,0.28 to the respective frequency ratios 8/25, 4/25, 6/25, 7/25, we see that the distribution is correct as these are equivalent.\n",
    "\n",
    "Any 2-mer that did not appear in s such as AC and AG have the correct distribution of 0.25 each which they get from the initial values. I picked the 2-mer CG at random to check whether a 2-mer that is in s has the correct distribution. The context list of CG (printed above) is \"AA\", so the total counts of A,C,G,T in this function should be 3,1,1,1 respectively, which would give a distribution of 3/6,1/6,1/6 and 1/6. We see that the distribution for CG in the output is equivalent to the aforementioned values as desired."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Write class ```MarkovProb``` that given the $k$-th order Markov chain developed above to the constructor, its method ```probability``` computes the probability of a given input DNA sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.346222Z",
     "start_time": "2019-07-08T22:04:23.330779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of sequence ATGATATCATCGACGATGTAG is 2.831270190340017e-10\n",
      "{'A': 0.32, 'C': 0.16, 'G': 0.24, 'T': 0.28}\n",
      "Probability of sequence G is 0.24\n",
      "Probability of sequence GT is 0.06720000000000001 and should be 0.06720000000000001\n",
      "{'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
      "Probability of sequence ACC is 0.01024 and should be 0.01024\n"
     ]
    }
   ],
   "source": [
    "class MarkovProb:\n",
    "    def __init__(self, k, zeroth, kth):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "        \n",
    "    def probability(self, s):\n",
    "        prob  = 1\n",
    "        if len(s) < self.k:\n",
    "            for i in range(len(s)):\n",
    "                prob *= self.zeroth[s[i]]\n",
    "        else:\n",
    "            for i in range(self.k):\n",
    "                prob *= self.zeroth[s[i]]\n",
    "            for i in range(self.k,len(s)):\n",
    "                prob *= self.kth[s[i-self.k:i]][s[i]]\n",
    "        return prob\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    mc = MarkovProb(2, zeroth2, kth_2)\n",
    "    print(f\"Probability of sequence {s} is {mc.probability(s)}\")\n",
    "\n",
    "    print(zeroth2)\n",
    "    s1 = \"G\"\n",
    "    print(f\"Probability of sequence {s1} is {mc.probability(s1)}\")\n",
    "\n",
    "    s2 = \"GT\"\n",
    "    print(f\"Probability of sequence {s2} is {mc.probability(s2)} and should be\", zeroth2[\"G\"]*zeroth2[\"T\"])\n",
    "\n",
    "    print(kth_2[\"AC\"])\n",
    "    s3 = \"ACC\"\n",
    "    print(f\"Probability of sequence {s3} is {mc.probability(s3)} and should be\", zeroth2[\"A\"]*zeroth2[\"C\"]*kth_2[\"AC\"][\"C\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "If string s has length smaller than k, then all probabilities would given bu the zeroth dictionary. So i ran a for loop for each character for s and looked up the character in the zeroth dictionary. Each value looked up was multiplied together giving the probability.\n",
    "Otherwise, I did the same thing as mentioned above for the first k characters of s using a for loop for them. For the remaining characters of s, I ran a for loop for each remaining character i, where I first looked up the substring formed by the k characters before i in the kth dictionary to get the probability distribution of each base and then looked up the base i in this distribution to get its probability. This number was multiplitied to the probability variable which was the result of the function."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Although the given example, ATGATATCATCGACGATGTAG, outputs a probability that would make sense, it would be tedious to check if the product is accurate. So I tested examples of length 1,2 and 3 so that I can manually check the probability and also because 1 is less than k and would test a different case in the code. For the string of length 1, I simply looked up the character in the zeroth dictionary to get the expected answer which indeed matches the output. I did the same for the characters in the string of length 2 and multiplied their probabilities together, which also matches the output. For the string of length three, I got the first two probabilities by looking up the first two characters in the zeroth dictionary and to get the probability of the third character, I looked up its probability in the dictionary that is the probability distribution of the first two characters in the kth dictionary. I multiplied these three values which also matched the output as desired."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the last assignment you might end up in trouble with precision, as multiplying many small probabilities gives a really small number in the end. There is an easy fix by using so-called log-transform. \n",
    "Consider computation of $P=s_1 s_2 \\cdots s_n$, where $0\\leq s_i\\leq 1$ for each $i$. Taking logarithm in base 2 from both sides gives $\\log _2 P= \\log _2 (s_1 s_2 \\cdots s_n)=\\log_2 s_1 + \\log_2 s_2 + \\cdots \\log s_n= \\sum_{i=1}^n \\log s_i$, with repeated application of the property that the logarithm of a multiplication of two numbers is the sum of logarithms of the two numbers taken separately. The results is abbreviated as log-probability.\n",
    "\n",
    "15. Write class ```MarkovLog``` that given the $k$-th order Markov chain developed above to the constructor, its method ```log_probability``` computes the log-probability of a given input DNA sequence. Run your program with $T=$ `ATGATATCATCGACGATGTAG` and $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.390453Z",
     "start_time": "2019-07-08T22:04:23.379760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probability of sequence ATGATATCATCGACGATGTAG is -31.717831515538315\n",
      "{'A': 0.32, 'C': 0.16, 'G': 0.24, 'T': 0.28}\n",
      "Log probability of sequence G is -2.0588936890535687 and should be -2.0588936890535687\n",
      "Log probability of sequence GT is -3.895394956770689 and should be -3.895394956770689\n",
      "{'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
      "Log probability of sequence ACC is -6.609640474436812 and should be -6.609640474436812\n"
     ]
    }
   ],
   "source": [
    "class MarkovLog(object):\n",
    "\n",
    "    def __init__(self, k, zeroth, kth):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "        \n",
    "    def log_probability(self, s):\n",
    "        prob  = 0\n",
    "        if len(s) < self.k:\n",
    "            for i in range(len(s)):\n",
    "                prob += np.log2(self.zeroth[s[i]])\n",
    "        else:\n",
    "            for i in range(self.k):\n",
    "                prob += np.log2(self.zeroth[s[i]])\n",
    "            for i in range(self.k,len(s)):\n",
    "                prob += np.log2(self.kth[s[i-self.k:i]][s[i]])\n",
    "        return prob\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    mc = MarkovLog(2, zeroth2, kth_2)\n",
    "    s=\"ATGATATCATCGACGATGTAG\"\n",
    "    print(f\"Log probability of sequence {s} is {mc.log_probability(s)}\")\n",
    "\n",
    "    print(zeroth2)\n",
    "    s1 = \"G\"\n",
    "    print(f\"Log probability of sequence {s1} is {mc.log_probability(s1)} and should be {np.log2(zeroth2[s1])}\")\n",
    "\n",
    "    s2 = \"GT\"\n",
    "    print(f\"Log probability of sequence {s2} is {mc.log_probability(s2)} and should be\", np.log2(zeroth2[\"G\"])+np.log2(zeroth2[\"T\"]))\n",
    "\n",
    "    print(kth_2[\"AC\"])\n",
    "    s3 = \"ACC\"\n",
    "    print(f\"Log probability of sequence {s3} is {mc.log_probability(s3)} and should be\", np.log2(zeroth2[\"A\"])+np.log2(zeroth2[\"C\"])+np.log2(kth_2[\"AC\"][\"C\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "I used a similar approach as the previous question in this question. For the case that the size of s is smaller than k, I found the log of the probability of each character in s where the probability was obtained by looking up the character in the zeroth dictionary. These values were then added up and returned. Otherwise, I ran a loop that does the same as in the previous case for the first k characters, and for the remaining characters, I looked up the substring formed by the k characters before i in the kth dictionary and then looked up the character i in the resulting dictionary. This would give me a probability which I then found the log of and added to the output value to be returned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Just like the previous question, the first test is difficult to verify as it is a long string but we see that it does output a value that looks roughly correct. I tested the function on three strings of length 1,2,3 to check all the cases of my code and also because I can manually compute these values and compare them to the output. I looked up the characters in the zeroth and kth dictionaries as needed to get the probabilities I need, found their log and added them together. We see that the function gives the right answer for these three tests."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if you try to use the code so far for very large inputs, you might observe that the concatenation of symbols following a context occupy considerable amount of space. This is unnecessary, as we only need the frequencies. \n",
    "\n",
    "16. Optimize the space requirement of your code from exercise 13 for the $k$-th order Markov chain by replacing the concatenations by direct computations of the frequencies. Implement this as the\n",
    "  ```better_context_probabilities``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.422302Z",
     "start_time": "2019-07-08T22:04:23.416330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT: {'A': 0.2222222222222222, 'C': 0.3333333333333333, 'G': 0.3333333333333333, 'T': 0.1111111111111111}\n",
      "TG: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.3333333333333333}\n",
      "GA: {'A': 0.14285714285714285, 'C': 0.2857142857142857, 'G': 0.14285714285714285, 'T': 0.42857142857142855}\n",
      "TA: {'A': 0.16666666666666666, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.3333333333333333}\n",
      "TC: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.16666666666666666}\n",
      "CA: {'A': 0.2, 'C': 0.2, 'G': 0.2, 'T': 0.4}\n",
      "CG: {'A': 0.5, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.16666666666666666}\n",
      "AC: {'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
      "GT: {'A': 0.4, 'C': 0.2, 'G': 0.2, 'T': 0.2}\n",
      "AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "CC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "CT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "TT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "Here are the kmers not in s:\n",
      "AA\n",
      "CC\n",
      "CT\n",
      "GC\n",
      "GG\n",
      "TT\n",
      "Let's check the bases that follow CA: ['T']\n"
     ]
    }
   ],
   "source": [
    "def better_context_probabilities(s, k):\n",
    "    CL = {}\n",
    "\n",
    "    for i in range(len(s)-k):\n",
    "        curr_kmer = s[i:i+k]\n",
    "        if curr_kmer in CL:\n",
    "            CL[curr_kmer][s[i+k]] += 1\n",
    "        else:\n",
    "            CL[curr_kmer] = {\"A\":1, \"C\":1, \"G\":1, \"T\":1}\n",
    "            CL[curr_kmer][s[i+k]] += 1\n",
    "    for i in product(\"ACGT\", repeat=k):\n",
    "        kmer = \"\".join(i)\n",
    "        if kmer not in CL:\n",
    "            CL[kmer] = {\"A\":1, \"C\":1, \"G\":1, \"T\":1}\n",
    "\n",
    "    CP = {}\n",
    "    for context in CL:\n",
    "        symbols = CL[context]\n",
    "        total = symbols[\"A\"]+symbols[\"C\"]+symbols[\"G\"]+symbols[\"T\"]\n",
    "        prob_A = symbols[\"A\"]/total\n",
    "        prob_C = symbols[\"C\"]/total\n",
    "        prob_G = symbols[\"G\"]/total\n",
    "        prob_T = symbols[\"T\"]/total\n",
    "        CP[context] = {\"A\":prob_A, \"C\":prob_C, \"G\":prob_G, \"T\":prob_T}\n",
    "    return CP\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    d = better_context_probabilities(s, k)\n",
    "    print(\"\\n\".join(f\"{k}: {v}\" for k, v in d.items()))\n",
    "    print(\"Here are the kmers not in s:\")\n",
    "    for kmer in d: \n",
    "        if kmer not in s: \n",
    "            print(kmer)\n",
    "    print(\"Let's check the bases that follow CA:\", end=\" \")\n",
    "    print(re.findall(r\"CA([ACGT])\", s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "I first looped through each k-mer in the s to count the frequencies of each base after each k-mer. For each k-mer, I increased the count of the base proceeding it by 1 in the dictionary that is the value of the k-mer in my frequency dictionary, CL. If that k-mer is not already a key in my dictionary, I put it in and initialized the counts to 1 as suggested, before adding 1 for the base that proceeds the k-mer in s. By the end of this loop, I had a dictionary of counts of each base that proceeded each k-mer. This loop might not have added a key for every possible k-mer since s might not contain all possible k-mers. So I looped through all possible k-mers which I obtained using the product function and added any k-mers that were not already added, initializing the counts to 1.\n",
    "\n",
    "I then looped through  each k-mer in my counts dictionary CL, added up the counts of each base to get the total and divided the total by each of the four counts to change the counts into probability. Due to the initialization being 1 for each base, the total of the counts would have never been 0 so I did not need to worry about zero division error. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Note that for all the k-mers not in s, the counts would have been 1 which implies the probabilities would have been 0.25 for each base and that is indeed the case as we can see.\n",
    "\n",
    "To check an arbitrary base other than the ones that are not in s, let us check CA. Looking at all the characters that follow CA (printed above), we see that T is the only one. So the counts for A,C,G,T would be 1,1,1 and 2 respectively, which would give probabilities of 0.2,0.2,0.2 and 0.4 which is correct.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the earlier approach of explicit concatenation of symbols following a context suffered from inefficient use of space, it does have a benefit of giving another much simpler strategy to sample from the distribution: \n",
    "observe that an element of the concatenation taken uniformly randomly is sampled exactly with the correct probability. \n",
    "\n",
    "17. Revisit the solution 12 and modify it to directly sample from the concatenation of symbols following a context. The function ```np.random.choice``` may be convenient here. Implement the modified version as the new `SimpleMarkovChain` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.462556Z",
     "start_time": "2019-07-08T22:04:23.453101Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATATCGATAT\n",
      "ATA\n",
      "A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class SimpleMarkovChain(object):\n",
    "    def __init__(self, s, k):\n",
    "        self.s = s\n",
    "        self.k = k\n",
    "        \n",
    "\n",
    "    def generate(self, n, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        CL = context_list(self.s,self.k)\n",
    "        res = \"\"\n",
    "        if n<self.k:\n",
    "            for i in range(n):\n",
    "                res += np.random.choice(np.array(list(self.s)))\n",
    "        else:\n",
    "            for i in range(self.k):\n",
    "                res += np.random.choice(np.array(list(self.s)))\n",
    "            while len(res) < n:\n",
    "                context = res[-1*self.k:]\n",
    "                if context in CL:\n",
    "                    res += np.random.choice(np.array(list(CL[context])))\n",
    "                else:\n",
    "                    res += np.random.choice(np.array(list(self.s)))\n",
    "        return res\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    mc = SimpleMarkovChain(s, k)\n",
    "    print(mc.generate(10, 7))\n",
    "    print(mc.generate(3, 7))\n",
    "    print(mc.generate(1, 7))\n",
    "    print(mc.generate(0, 7))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "To generate the first k characters or for all characters if n is less than k, I ran a loop where each time, I used np.random.choice to choose a random character of s by converting s into an array of its characters. This array represents the distribution of each base in s. I concatenated each generated character into a string called res. For the reamaining characters of my resulting string, I ran a while loop that concatenated a character to res until res has the correct length of n. To generate this character, I used np.random.choice again but this time, I used the string obtained by looking up the substring of tf last k characters of res so far in the context_list dictionary to get a string representing the distribution of bases. Plugging in this string into choice, I was able to generate the character. All the generated characters were concatenated to res which was the output. By using random.seed, I made sure that the random generation was always the same given a seed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "I was not sure how to test whether the randomly generated sequence followed the correct distributions as it would require many manual computations. We can however see that random dna sequences of the right length are being generated. Also, running it multiple times is producing the same generation which means the seed is working correctly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-mer index\n",
    "\n",
    "Our $k$-th order Markov chain can now be modified to a handy index structure called $k$-mer index. This index structure associates to each $k$-mer its list of occurrence positions in DNA sequence $T$.  Given a query $k$-mer $W$, one can thus easily list all positions $i$ with  $T[i..k-1]=W$.\n",
    "\n",
    "18. Implement function ```kmer_index``` inspired by your earlier code for the $k$-th order Markov chain. Test your program with `ATGATATCATCGACGATGTAG` and $k=2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.504405Z",
     "start_time": "2019-07-08T22:04:23.494537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using string:\n",
      "ATGATATCATCGACGATGTAG\n",
      "012345678901234567890\n",
      "\n",
      "2-mer index is:\n",
      "{'AT': [0, 3, 5, 8, 15], 'TG': [1, 16], 'GA': [2, 11, 14], 'TA': [4, 18], 'TC': [6, 9], 'CA': [7], 'CG': [10, 13], 'AC': [12], 'GT': [17], 'AG': [19]}\n",
      "all indices in dictionary:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "length of s:  21\n"
     ]
    }
   ],
   "source": [
    "def kmer_index(s, k):\n",
    "    index_dict = {}\n",
    "    for i in range(len(s)-k+1):\n",
    "        curr_kmer = s[i:i+k]\n",
    "        if curr_kmer in index_dict:\n",
    "            index_dict[curr_kmer].append(i)\n",
    "        else:\n",
    "            index_dict[curr_kmer] = [i]\n",
    "    return index_dict\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"Using string:\")\n",
    "    print(s)\n",
    "    print(\"\".join([str(i%10) for i in range(len(s))]))\n",
    "    print(f\"\\n{k}-mer index is:\")\n",
    "    d=kmer_index(s, k)\n",
    "    print(dict(d))\n",
    "    all_indices = []\n",
    "    for kmer in d: all_indices += d[kmer]\n",
    "    print(\"all indices in dictionary: \", sorted(all_indices))\n",
    "    print(\"length of s: \", len(s))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "I initialized and empty dictionary and looped through the starting position of each k-mer in s which goes from 0 to len(s)-k. If the k-mer is not in the dictionary already, I added it to the dictionary with its value being a list containing the starting position of the k-mer. If the k-mer is in the dictinary already, I appended the starting position of the current k-mer to the list that is the value of this k-mer in the dictionary. This dictionary is returned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Using the numbers printed below the string s, we can check that the correct indices have been appended to the values of each k-mer. I also checked if all the indices have been accounted for in all the lists in the dictionary and indeed we see that all the possible indices (0-19) are included. The length of s is 21 so there are 19 2-mers in s."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of probability distributions\n",
    "\n",
    "Now that we know how to learn probability distributions from data, we might want to compare two such distributions, for example, to test if our programs work as intended. \n",
    "\n",
    "Let $P=\\{p_1,p_2,\\ldots, p_n\\}$ and $Q=\\{q_1,q_2,\\ldots, q_n\\}$ be two probability distributions for the same set of $n$ events. This means $\\sum_{i=1}^n p_i=\\sum_{i=1}^n q_i=1$, $0\\leq p_j \\leq 1$, and $0\\leq q_j \\leq 1$ for each event $j$. \n",
    "\n",
    "*Kullback-Leibler divergence* is a measure $d()$ for the *relative entropy* of $P$ with respect to $Q$ defined as \n",
    "$d(P||Q)=\\sum_{i=1}^n p_i \\log\\frac{p_i}{q_i}$.\n",
    "\n",
    "\n",
    "This measure is always non-negative, and 0 only when $P=Q$. It can be interpreted as the gain of knowing $Q$ to encode $P$. Note that this measure is not symmetric.\n",
    "\n",
    "19. Write function ```kullback_leibler``` to compute $d(P||Q)$. Test your solution by generating a random RNA sequence\n",
    "  encoding the input protein sequence according to the input codon adaptation probabilities.\n",
    "  Then you should learn the codon adaptation probabilities from the RNA sequence you generated.\n",
    "  Then try the same with uniformly random RNA sequences (which don't have to encode any\n",
    "  specific protein sequence). Compute the relative entropies between the\n",
    "  three distribution (original, predicted, uniform) and you should observe a clear difference.\n",
    "  Because $d(P||Q)$ is not symmetric, you can either print both $d(P||Q)$ and $d(Q||P)$,\n",
    "  or their average.\n",
    "  \n",
    "  This problem may be fairly tricky. Only the `kullback_leibler` function is automatically tested. The codon probabilities is probably a useful helper function. The main guarded section can be completed by filling out the `pass` sections using tooling from previous parts and fixing the *placeholder* lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.557340Z",
     "start_time": "2019-07-08T22:04:23.539188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if the proteins are the same:  True\n",
      "d(original || predicted) = 95.08108417744201\n",
      "d(predicted || original) = -4.243547580723664\n",
      "\n",
      "d(original || uniform) = 97.80864294334887\n",
      "d(uniform || original) = -4.102470506137899\n",
      "\n",
      "d(predicted || uniform) = 0.06900172357165896\n",
      "d(uniform || predicted) = 0.07112790198184574\n"
     ]
    }
   ],
   "source": [
    "def codon_probabilities(rna):\n",
    "    \"\"\"\n",
    "    Given an RNA sequence, simply calculates the proability of\n",
    "    all 3-mers empirically based on the sequence\n",
    "    \"\"\"\n",
    "    codon_prob_dict = {\"\".join(codon): 0 for codon in product(\"ACGU\", repeat=3)}\n",
    "    for i in range(len(rna)-2):\n",
    "        codon_prob_dict[rna[i:i+3]] += 1\n",
    "    total_3mers = len(rna)-2\n",
    "    for codon in codon_prob_dict:\n",
    "        codon_prob_dict[codon] /= total_3mers\n",
    "    return codon_prob_dict\n",
    "    \n",
    "def kullback_leibler(p, q):\n",
    "    \"\"\"\n",
    "    Computes Kullback-Leibler divergence between two distributions.\n",
    "    Both p and q must be dictionaries from events to probabilities.\n",
    "    The divergence is defined only when q[event] == 0 implies p[event] == 0.\n",
    "    \"\"\"\n",
    "    KL_divergence = 0\n",
    "    for i in p:\n",
    "        if p[i] != 0.0:\n",
    "            KL_divergence += p[i]*np.log2(p[i]/q[i])\n",
    "    return KL_divergence\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    aas = list(\"*ACDEFGHIKLMNPQRSTVWY\") # List of amino acids\n",
    "    n = 10000\n",
    "    \n",
    "    # generate a random protein and some associated rna\n",
    "    protein = \"\".join(choice(aas, n))   \n",
    "    prot_to_rna = ProteinToRandomRNA()\n",
    "    assoc_rna = prot_to_rna.convert(protein)\n",
    "    \n",
    "    # Maybe check that converting back to protein results in the same sequence\n",
    "    assoc_protein = rna_to_prot(assoc_rna)\n",
    "    print(\"Testing if the proteins are the same: \",protein == assoc_protein)\n",
    "    \n",
    "    # Calculate codon probabilities of the rna sequence\n",
    "    cp_predicted = codon_probabilities(assoc_rna) # placeholder call\n",
    "    \n",
    "    # Calculate codon probabilities based on the codon usage table\n",
    "    cp_orig = get_probabability_dict()# placeholder dict\n",
    "    \n",
    "    # Create a completely random RNA sequence and get the codon probabilities\n",
    "    random_rna = \"\".join(choice(list(\"AGCU\"), n))\n",
    "    cp_uniform = codon_probabilities(random_rna) # placeholder call\n",
    "    \n",
    "    print(\"d(original || predicted) =\", kullback_leibler(cp_orig, cp_predicted))\n",
    "    print(\"d(predicted || original) =\", kullback_leibler(cp_predicted, cp_orig))\n",
    "    print()\n",
    "    print(\"d(original || uniform) =\", kullback_leibler(cp_orig, cp_uniform))\n",
    "    print(\"d(uniform || original) =\", kullback_leibler(cp_uniform, cp_orig))\n",
    "    print()\n",
    "    print(\"d(predicted || uniform) =\", kullback_leibler(cp_predicted, cp_uniform))\n",
    "    print(\"d(uniform || predicted) =\", kullback_leibler(cp_uniform, cp_predicted))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "I ran a for loop through each key of p, knowing that the keys of p and q are the same. For each key of p (and q), I executed the computation p_i(log(p_i/q_i)) if p_i is not 0 since log(0) does not exist. I added the result to a vairable that I intialized to 0 to get the total sum of all terms. This variable was returned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Looking at the tests, we can see that not all of the distributions are non-negative which either means that I have an error in the calculations which I could not locate or that the probabilities are too small to get an accurate sum of logs.\n",
    "It appears that knowing the predicted and uniform distributions helps in encoding the original distribution greatly but the original distribution does not help the other two. The predicted and uniform distributions don't seem to help encode eachother since both their divergences are near zero."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stationary and equilibrium distributions (extra)\n",
    "\n",
    "Let us consider a Markov chain of order one on the set of nucleotides.\n",
    "Its transition probabilities can be expressed as a $4 \\times 4$ matrix\n",
    "$P=(p_{ij})$, where the element $p_{ij}$ gives the probability of the $j$th nucleotide\n",
    "on the condition the previous nucleotide was the $i$th. An example of a transition matrix\n",
    "is\n",
    "\n",
    "\\begin{array}{l|rrrr}\n",
    " &     A &    C &     G &    T \\\\\n",
    "\\hline\n",
    "A &  0.30 &  0.0 &  0.70 &  0.0 \\\\\n",
    "C &  0.00 &  0.4 &  0.00 &  0.6 \\\\\n",
    "G &  0.35 &  0.0 &  0.65 &  0.0 \\\\\n",
    "T &  0.00 &  0.2 &  0.00 &  0.8 \\\\\n",
    "\\end{array}.\n",
    "\n",
    "A distribution $\\pi=(\\pi_1,\\pi_2,\\pi_3,\\pi_4)$ is called *stationary*, if\n",
    "$\\pi = \\pi P$ (the product here is matrix product).\n",
    "\n",
    "20. Write function ```get_stationary_distributions``` that gets a transition matrix as parameter,\n",
    "  and returns the list of stationary distributions. You can do this with NumPy by\n",
    "  first taking transposition of both sides of the above equation to get equation\n",
    "  $\\pi^T = P^T \\pi^T$. Using numpy.linalg.eig take all eigenvectors related to\n",
    "  eigenvalue 1.0. By normalizing these vectors to sum up to one get the stationary distributions\n",
    "  of the original transition matrix. In the ```main``` function print the stationary distributions\n",
    "  of the above transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.591644Z",
     "start_time": "2019-07-08T22:04:23.580588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.254, +0.451, +0.267, -0.493\n",
      "+0.243, +0.496, +0.084, -0.143\n"
     ]
    }
   ],
   "source": [
    "def get_stationary_distributions(transition):\n",
    "    \"\"\"\n",
    "    The function get a transition matrix of a degree one Markov chain as parameter.\n",
    "    It returns a list of stationary distributions, in vector form, for that chain.\n",
    "    \"\"\"\n",
    "    return np.random.rand(2, 4) - 0.5\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    transition=np.array([[0.3, 0, 0.7, 0],\n",
    "                         [0, 0.4, 0, 0.6],\n",
    "                         [0.35, 0, 0.65, 0],\n",
    "                         [0, 0.2, 0, 0.8]])\n",
    "    print(\"\\n\".join(\n",
    "        \", \".join(\n",
    "            f\"{pv:+.3f}\"\n",
    "            for pv in p) \n",
    "        for p in get_stationary_distributions(transition)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Implement the `kl_divergence` function below so that the main guarded code runs properly. Using your modified Markov chain generator generate a nucleotide sequence $s$ of length $10\\;000$. Choose prefixes of $s$ of lengths $1, 10, 100, 1000$, and $10\\;000$. For each of these prefixes find out their nucleotide distribution (of order 0) using your earlier tool. Use 1 as the pseudo count. Then, for each prefix, compute the KL divergence between the initial distribution and the normalized nucleotide distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.635060Z",
     "start_time": "2019-07-08T22:04:23.618890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition probabilities are:\n",
      "[[0.3  0.   0.7  0.  ]\n",
      " [0.   0.4  0.   0.6 ]\n",
      " [0.35 0.   0.65 0.  ]\n",
      " [0.   0.2  0.   0.8 ]]\n",
      "Stationary distributions:\n",
      "[[-0.00537851  0.11101195 -0.49957744 -0.30492211]\n",
      " [ 0.01817657  0.39433265 -0.49701862 -0.0581689 ]]\n",
      "Using [0.02, 0.39, -0.50, -0.06] as initial distribution\n",
      "\n",
      "KL divergence of stationary distribution prefix of length     1 is 0.33062863\n",
      "KL divergence of stationary distribution prefix of length    10 is 0.38992107\n",
      "KL divergence of stationary distribution prefix of length   100 is 0.61068418\n",
      "KL divergence of stationary distribution prefix of length  1000 is 0.98421894\n",
      "KL divergence of stationary distribution prefix of length 10000 is 0.59148237\n"
     ]
    }
   ],
   "source": [
    "def kl_divergences(initial, transition):\n",
    "    \"\"\"\n",
    "    Calculates the the Kullback-Leibler divergences between empirical distributions\n",
    "    generated using a markov model seeded with an initial distributin and a transition \n",
    "    matrix, and the initial distribution.\n",
    "    Sequences of length [1, 10, 100, 1000, 10000] are generated.\n",
    "    \"\"\"\n",
    "    return zip([1, 10, 100, 1000, 10000], np.random.rand(5))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transition=np.array([[0.3, 0, 0.7, 0],\n",
    "                         [0, 0.4, 0, 0.6],\n",
    "                         [0.35, 0, 0.65, 0],\n",
    "                         [0, 0.2, 0, 0.8]])\n",
    "    print(\"Transition probabilities are:\")\n",
    "    print(transition)\n",
    "    stationary_distributions = get_stationary_distributions(transition)\n",
    "    print(\"Stationary distributions:\")\n",
    "    print(np.stack(stationary_distributions))\n",
    "    initial = stationary_distributions[1]\n",
    "    print(\"Using [{}] as initial distribution\\n\".format(\", \".join(f\"{v:.2f}\" for v in initial)))\n",
    "    results = kl_divergences(initial, transition)\n",
    "    for prefix_length, divergence in results: # iterate on prefix lengths in order (1, 10, 100...)\n",
    "        print(\"KL divergence of stationary distribution prefix \" \\\n",
    "              \"of length {:5d} is {:.8f}\".format(prefix_length, divergence))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "fill in"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "fill in"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Implement the following in the ```main``` function.\n",
    "Find the stationary distribution for the following transition matrix:  \n",
    "\n",
    "\\begin{array}{ l | r r r r}\n",
    " & A &     C &     G &     T \\\\\n",
    "\\hline\n",
    "A &  0.30 &  0.10 &  0.50 &  0.10 \\\\\n",
    "C &  0.20 &  0.30 &  0.15 &  0.35 \\\\\n",
    "G &  0.25 &  0.15 &  0.20 &  0.40 \\\\\n",
    "T &  0.35 &  0.20 &  0.40 &  0.05 \\\\\n",
    "\\end{array}\n",
    "\n",
    "Since there is only one stationary distribution, it is called the *equilibrium distribution*.\n",
    "Choose randomly two nucleotide distributions. You can take these from your sleeve or\n",
    "sample them from the Dirichlet distribution. Then for each of these distributions\n",
    "as the initial distribution of the Markov chain, repeat the above experiment.\n",
    "\n",
    "The `main` function should return tuples, where the first element is the (random) initial distribution and the second element contains the results as a list of tuples where the first element is the kl divergence and the second element the empirical nucleotide distribution, for the different prefix lengths.\n",
    "\n",
    "The state distribution should converge to the equilibrium distribution no matter how we\n",
    "start the Markov chain! That is the last line of the tables should have KL-divergence very close to $0$ and an empirical distribution very close to the equilibrium distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.681300Z",
     "start_time": "2019-07-08T22:04:23.657345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition probabilities are:\n",
      "[[0.3  0.1  0.5  0.1 ]\n",
      " [0.2  0.3  0.15 0.35]\n",
      " [0.25 0.15 0.2  0.4 ]\n",
      " [0.35 0.2  0.4  0.05]]\n",
      "Equilibrium distribution:\n",
      "[-0.12974871  0.250996    0.35271711 -0.38187202]\n",
      "\n",
      "Using [-0.11956792 -0.03414162 -0.19941102 -0.24758042] as initial distribution:\n",
      "kl-divergence   empirical distribution\n",
      "0.37637114852   [ 0.28153457 -0.29691819  0.48676966  0.05713638]\n",
      "0.56404697319   [ 0.0088926  -0.15564204  0.03424995  0.00070839]\n",
      "0.45667336726   [ 0.29587369 -0.39647587  0.37758201 -0.4903873 ]\n",
      "0.35806329526   [0.36256878 0.40083195 0.18905145 0.20282102]\n",
      "0.03121525022   [ 0.29721744  0.14385157 -0.02082882 -0.17573513]\n",
      "\n",
      "Using [0.33204736 0.43776623 0.41229545 0.15427126] as initial distribution:\n",
      "kl-divergence   empirical distribution\n",
      "0.83861464076   [ 0.04612454 -0.45099859  0.39856767 -0.31792474]\n",
      "0.29395666369   [ 0.07573083 -0.19558419 -0.37272953  0.39743735]\n",
      "0.73765720222   [ 0.36292045 -0.25453473  0.48171657  0.00637594]\n",
      "0.40992860587   [-0.17814365  0.26003522  0.42608076 -0.43198001]\n",
      "0.86824442654   [-0.01379966 -0.27144583 -0.08604978 -0.42022418]\n"
     ]
    }
   ],
   "source": [
    "def main(transition, equilibrium_distribution):\n",
    "    vals = list(zip(np.random.rand(10), np.random.rand(10, 4) - 0.5))\n",
    "    return zip(np.random.rand(2, 4) - 0.5, \n",
    "               [vals[:5], vals[5:]])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transition = np.array([[0.3, 0.1, 0.5, 0.1],\n",
    "                           [0.2, 0.3, 0.15, 0.35],\n",
    "                           [0.25, 0.15, 0.2, 0.4],\n",
    "                           [0.35, 0.2, 0.4, 0.05]])\n",
    "    print(\"Transition probabilities are:\", transition, sep=\"\\n\")\n",
    "    stationary_distributions = get_stationary_distributions(transition)\n",
    "    # Uncomment the below line to check that there actually is only one stationary distribution\n",
    "    # assert len(stationary_distributions) == 1\n",
    "    equilibrium_distribution = stationary_distributions[0]\n",
    "    print(\"Equilibrium distribution:\")\n",
    "    print(equilibrium_distribution)\n",
    "    for initial_distribution, results in main(transition, equilibrium_distribution):\n",
    "        print(\"\\nUsing {} as initial distribution:\".format(initial_distribution))\n",
    "        print(\"kl-divergence   empirical distribution\")\n",
    "        print(\"\\n\".join(\"{:.11f}   {}\".format(di, kl) for di, kl in results))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea of solution\n",
    "\n",
    "fill in"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "fill in"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "598.85px",
    "left": "1223px",
    "right": "20px",
    "top": "121px",
    "width": "353px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
